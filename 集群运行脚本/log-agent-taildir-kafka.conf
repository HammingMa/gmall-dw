##### 日志文件 上传到kafka channel  flume 配置文件

## agent 名字为 a1
## source 名字为 r1
a1.sources = r1
## 有两个channel 分别为c1 c2
a1.channels = c1 c2

## source r1 的类型为 tail dir
a1.sources.r1.type = TAILDIR
## 文件组的名字Wie f1
a1.sources.r1.filegroups = f1
## f1 监控的文件为 /tmp/logs/ 下一log.* 开头的文件  这里是正则表达式匹配
a1.sources.r1.filegroups.f1 = /tmp/logs/app.*
## positionFile 断点续传的标记文件存储的的位置
a1.sources.r1.positionFile = /opt/flume/positionFlie/taildir_position.json
a1.sources.r1.channels = c1 c2

## selector
## selector 的类型为 multiplexing  多个channel
a1.sources.r1.selector.type = multiplexing
## 取header中的topic 属性
a1.sources.r1.selector.header = topic
## topic_start 发送到c1
a1.sources.r1.selector.mapping.topic_start = c1
## topic_event 发送到c2
a1.sources.r1.selector.mapping.topic_event = c2

## interceptors 拦截器 
## 两个拦截器 i1 i2
a1.sources.r1.interceptors = i1 i2
a1.sources.r1.interceptors.i1.type = com.mzh.gmall.dw.flume.interceptor.LogETLInterceptor$Builder
a1.sources.r1.interceptors.i2.type = com.mzh.gmall.dw.flume.interceptor.LogTypeInterceptor$Builder


## channel kafka
## c1  类型为 kafka channel
a1.channels.c1.type = org.apache.flume.channel.kafka.KafkaChannel
## kafka 服务器地址 bootstrap
a1.channels.c1.kafka.bootstrap.servers = hdp1:9092,hdp2:9092,hdp3:9092
## topic 名称
a1.channels.c1.kafka.topic = topic_start
## 只接收 body的内容
a1.channels.c1.parseAsFlumeEvent = false

## channel kafka
## c2  类型为 kafka channel
a1.channels.c2.type = org.apache.flume.channel.kafka.KafkaChannel
## kafka 服务器地址 bootstrap
a1.channels.c2.kafka.bootstrap.servers = hdp1:9092,hdp2:9092,hdp3:9092
## topic 名称
a1.channels.c2.kafka.topic = topic_event
## 只接收 body的内容
a1.channels.c2.parseAsFlumeEvent = false